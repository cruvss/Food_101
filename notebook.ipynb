{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "<h1 style=\"font-size:250%; font-family:cursive; color:#ff6666;\"> <b>1. Getting Data Ready <a id=\"0\"></a></b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "from pathlib import Path "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Creating train and test directory and exploring them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = Path(\"data/food-101\")\n",
    "train_dir  = image_path/\"Train\"\n",
    "test_dir   = image_path/\"Test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking number of image samples in each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in Training set is: 70700\n",
      "Number of images in Testing set is: 30300\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of images in Training set is: {len(list(train_dir.glob('*/*.jpg')))}\\nNumber of images in Testing set is: {len(list(test_dir.glob('*/*.jpg')))}\")\n",
    "# this is memory consuming as we have to make list here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in Training set is: 70700\n",
      "Number of images in Testing set is: 30300\n"
     ]
    }
   ],
   "source": [
    "train_image_count = sum(1 for _ in train_dir.rglob('*.jpg'))\n",
    "test_image_count = sum(1 for _ in test_dir.rglob('*.jpg'))\n",
    "\n",
    "#rglob recursively seraches for .jpg file. \n",
    "\n",
    "print(f\"Number of images in Training set is: {train_image_count}\")\n",
    "print(f\"Number of images in Testing set is: {test_image_count}\")\n",
    "\n",
    "#memory efficient alternative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Finding Class Labels and converting them to class index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = sorted(os.listdir(train_dir)) \n",
    "class_to_idx = { name:i for i, name in enumerate(class_names)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 style = \"font-size:250%; family:'cursive'; color:#ff6666\"> 2. Create DataLoader <a id=2></a></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch import nn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Create Transforms using pretrained model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassification(\n",
       "    crop_size=[224]\n",
       "    resize_size=[256]\n",
       "    mean=[0.485, 0.456, 0.406]\n",
       "    std=[0.229, 0.224, 0.225]\n",
       "    interpolation=InterpolationMode.BICUBIC\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before we Create dataloader lets select an pretrained model so that we can get the transforms applied on that model.\n",
    "\n",
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "auto_transforms = weights.transforms()\n",
    "auto_transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Create custom dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets,transforms\n",
    "from torch.utils.data import Dataset \n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using ImageFolder for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_img = datasets.ImageFolder(root =train_dir,\n",
    "                                         transform = auto_transforms,\n",
    "                                         target_transform = None\n",
    ")\n",
    "#bad bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self,target_dir,transform= None):\n",
    "        self.paths = list(Path(target_dir).glob(\"*/*.jpg\"))\n",
    "        self.transform = transform\n",
    "        self.classes = sorted(os.listdir(target_dir))\n",
    "        self.class_to_idx = {name:i for i,name in enumerate(self.classes)}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return(len(self.paths))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.paths[idx])\n",
    "        class_name = self.paths[idx].parent.stem\n",
    "        class_idx = self.class_to_idx[class_name]\n",
    "\n",
    "        if self.transform:\n",
    "            return self.transform(img), class_idx\n",
    "        \n",
    "        else:\n",
    "            return img, class_idx\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageDataset(target_dir=train_dir, transform = auto_transforms)\n",
    "test_dataset = ImageDataset(target_dir=test_dir, transform=auto_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying some random Images from the custom dataset we created.abs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "food101",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
